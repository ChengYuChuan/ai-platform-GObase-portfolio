# LLM Gateway Environment Variables
# Copy this file to .env and fill in your values

# Server Configuration
LLM_GATEWAY_SERVER_PORT=8080

# Logging
LLM_GATEWAY_LOG_LEVEL=info
LLM_GATEWAY_LOG_FORMAT=pretty

# OpenAI Configuration
LLM_GATEWAY_PROVIDERS_OPENAI_API_KEY=sk-your-openai-key-here

# Anthropic Configuration
LLM_GATEWAY_PROVIDERS_ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# Default Provider (openai, anthropic, ollama)
LLM_GATEWAY_PROVIDERS_DEFAULT=openai

# Ollama Configuration (if running locally)
LLM_GATEWAY_PROVIDERS_OLLAMA_BASE_URL=http://localhost:11434

# Redis (for caching - optional)
LLM_GATEWAY_CACHE_ENABLED=false
LLM_GATEWAY_CACHE_REDIS_ADDRESS=localhost:6379
